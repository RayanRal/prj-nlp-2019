# Нейромережі

У цьому завданні ви можете обрати одне з двох завдань, які треба виконати з використанням нейромереж:

1. Доробити парсер залежностей
2. Доробити класифікатор звернень до служби 1551

## Парсер залежностей

На основі FNN створіть класифікатор типу залежності. Для цього використайте:
- [UD-корпус для української мови](https://github.com/UniversalDependencies/UD_Ukrainian-IU/)
- парсер, який ви розробили в завданні 8 (або, якщо вам не вдалося реалізувати свій парсер, то можна взяти за основу [код із практичного заняття](https://github.com/vseloved/prj-nlp-2019/blob/master/lectures/08-dep-parser-uk.ipynb))
- [векторні представлення слів для української мови](http://lang.org.ua/en/models/#anchor4)

Крім того, переробіть свій парсер так, щоб замість використання ознак, визначених вручну, він покладався для вибору наступного переходу на передбачення LSTM-нейромережі, яка на вхід отримує поточні слова з тегами зі стеку та буферу (по 3 слова). Опис подібної мережі можна побачити у [цій статті](https://arxiv.org/pdf/1708.08959.pdf).

Обрахуйте якість класифікації та LAS для вашого парсера.

## Класифікатор звернень до служби 1551

Переробіть класифікатор звернень, який ви розробляли у завданні 9, так, щоб він використовував FNN на векторі документу та LSTM на векторах окремих слів. Порівняйте результати.

## Оцінка

За виконання одного з завдань ви можете отримати 100 балів. Якщо бажаєте, то можете виконати обидва і отримати 150 балів :)

Дедлайн: 11.05.2019

# Результат

Схоже, що я вже зробив варіант з поліпшенням класифікатора звернень до служби1551 в 
попередній домашці (останній вариант):

https://github.com/serge-sotnyk/prj-nlp-2019/tree/s.sotnyk-task09/students/SergeSotnyk/09-vectors

Ще спробував порівняти, що буде, якщо в парсері залежностей всі фічі оставити як є,
але у якості класифікатора взяти повнозв'язну нейромережу. Результат можна подивитися
у ноутбуці [NN-dep-parser-uk](NN-dep-parser-uk.ipynb). Відмічу тут декілька моментів:

- У варианті з логістичною регресією, застосовується досить багато фіч. То ж 
повнозв'язна мережа, навіть якщо брати не дуже багато нейронів, на першому шарі має
дуже багато вагових коефіцієнтів. Тому вона дуже склонна до оверфітінгу і треба
контролювати, щоб цього не було (я робив це за допомогою графіків якості відтворення
на тренувальній та валідаційній послідовностях).
- Ноутбук створений таким чином, щоб автоматично завантажувати всі дані в папку /data,
а також інсталювати необхідні пакети у випадку, якщо робимо в colab. Це дало мені
можливість параллельно з обробкою на своєму лептопі, ставити експерименти і в 
[Google Colab](https://colab.research.google.com). Через те, що там можна 
використовувати GPU/TPU середовище, аналогічні експерименти там тривали раза в 2
менше, ніж локально (хоча і треба стежити, щоб сесія не закрилася передчасно).
- Класифікатор на нейромережі робить достатньо повільно. Особливо через те, що там код
не векторизований. Я не став з цив щось робити - векторизувати можна, але не дуже 
просто. Для цього треба параллельно розбирати речення.
- На початковому етапі якість відновлення тренувальної вибірки була краще, ніж 
валідаційної. Це говорить про те, що в тренувальному сеті є "погані" приклади, яких
немає в валідаційній. Тобто, треба краще перемішати семпли, щоб збудувати більш
рівноміні сети. Або використати щось інакше - типу кроссвалідації. Я до цього не 
дійшов через те, що хотів просто порівняти два підходи в більш-менш однакових умовах
(тобто, що буде, якщо просто замінити класичну логістичну регресію на FFNN).

Ну і головне - результат:

Оригінальний вариант з LogisticRegression:

    Total: 16271
    Correctly defined: 11520
    UAS: 0.71
    
Вариант на нейромережі 

    model = models.Sequential()
    model.add(layers.Dense(16, activation='relu', 
                           kernel_regularizer=regularizers.l1_l2(0.00, 0.005), 
                           input_shape=(dim,)))
    model.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l1_l2(0.00, 0.005)))
    model.add(layers.Dense(len(labels_dict), activation='softmax'))

Дав такі показники:
    
    Total: 16271
    Correctly defined: 12230
    UAS: 0.75

Тобто, вийшло покращення у 4 відсотка.

Думаю, можна ще трохи покращити цей показник (десь до 0.76..0.77) невеличким тюнингом
гіперпараметрів, але краще таки буде перейти на інші фічі та рекурсивні або(та) 
конволюційні нейромережі.

## Update 2019-may-09:
Побачив, що при копіпасті з іншого ноутбука спочатку викорисав у якості валідаційної 
вибірки частину оригінального тренувального сета (а сам тренувальний сет було скорочено
на цю частину). То ж переробив правильно, та ще трохи погрався з параметрами (хоча,
вийшло практично также як і з попередніми). Зникла та ситуація, коли на валідаційному
сеті показники якості довго були краще, ніж на тренувальному.

Нові показники:

    Total: 16271
    Correctly defined: 12337
    UAS: 0.76