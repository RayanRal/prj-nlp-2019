{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, LSTM, TimeDistributed, Activation\n",
    "import keras_metrics\n",
    "\n",
    "from read_files import read_file\n",
    "from read_files import debug\n",
    "from read_files import files\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "uk_vectors_file = './data/news.lowercased.tokenized.word2vec.300d'\n",
    "\n",
    "uk_vectors = KeyedVectors.load_word2vec_format(uk_vectors_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_labels = ['dislocated', 'advcl', 'amod', 'obj', 'root', 'iobj', 'discourse', 'fixed', 'goeswith', 'det', 'list',\n",
    "              'ccomp', 'flat', 'mark', 'obl', 'punct', 'parataxis', 'acl', 'nummod', 'cc', 'csubj',\n",
    "              'compound', 'advmod', 'xcomp', 'appos', 'conj', 'expl', 'reparandum', 'aux', 'nmod', 'nsubj',\n",
    "              'case', 'vocative', 'cop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_trees(trees):\n",
    "    result = []\n",
    "    for tree in trees:\n",
    "        valid = True\n",
    "        for node in tree:\n",
    "            if type(node['head']) != int:\n",
    "                valid = False\n",
    "        if valid:\n",
    "            result.append(tree)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _get_embedding(node):\n",
    "    word = node.get('form').lower()\n",
    "    try:\n",
    "        return uk_vectors.get_vector(word)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _get_encoded_label(lbl):\n",
    "    if lbl not in all_labels:\n",
    "        return None\n",
    "    res = np.zeros(len(all_labels))\n",
    "    index = all_labels.index(lbl)\n",
    "    res[index] = 1\n",
    "    return res\n",
    "\n",
    "\n",
    "def _get_head_data(head_index, tree):\n",
    "    head = tree[head_index] if head_index < len(tree) else None\n",
    "    if not head:\n",
    "        return None, None, None\n",
    "    \n",
    "    head_embedding = _get_embedding(head)\n",
    "    head_label_enc = _get_encoded_label(head.get('deprel'))\n",
    "    return head, head_embedding, head_label_enc\n",
    "\n",
    "\n",
    "def _get_feature_vectors(word, tree):\n",
    "    child = word\n",
    "    result_vector = None\n",
    "    child_embedding = _get_embedding(child)\n",
    "    child_label_enc = _get_encoded_label(child.get('deprel'))\n",
    "    if child_label_enc is None:\n",
    "        return None, None\n",
    "    \n",
    "    head_1_index = child.get('head')\n",
    "    if not head_1_index:\n",
    "        return None, None\n",
    "    head_1, head_embedding_1, head_label_enc_1 = _get_head_data(head_1_index, tree)\n",
    "    if head_1 is None:\n",
    "        return None, None\n",
    "    \n",
    "    head_2_index = head_1.get('head')\n",
    "    if not head_2_index:\n",
    "        return None, None\n",
    "    _, head_embedding_2, head_label_enc_2 = _get_head_data(head_2_index, tree)\n",
    "    \n",
    "    if child_embedding is not None and head_embedding_1 is not None and head_label_enc_1 is not None and head_embedding_2 is not None and head_label_enc_2 is not None:\n",
    "        result_vector = np.hstack((child_embedding, head_embedding_1, head_embedding_2))\n",
    "        result_label = child_label_enc\n",
    "        return result_label, result_vector\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def _get_labels_features(filename):\n",
    "    trees = read_file(filename)\n",
    "    trees = filter_trees(trees)\n",
    "    labels, features = [], []\n",
    "    for tree in trees:\n",
    "        tree_features = []\n",
    "        tree_features_stepped = []\n",
    "        tree_labels = []\n",
    "        tree_labels_stepped = []\n",
    "\n",
    "        for word in tree:\n",
    "            label, feature = _get_feature_vectors(word, tree)\n",
    "            if feature is not None and label is not None:\n",
    "                tree_features.append(feature)\n",
    "                tree_labels.append(label)\n",
    "\n",
    "        if len(tree_features) > 0 and len(tree_labels) > 0:\n",
    "            for i in range(2, len(tree_features)):\n",
    "                step_1_features = tree_features[i-2]\n",
    "                step_2_features = tree_features[i-1]\n",
    "                step_3_features = tree_features[i]\n",
    "                \n",
    "                step_1_lbls = tree_labels[i-2]\n",
    "                step_2_lbls = tree_labels[i-1]\n",
    "                step_3_lbls = tree_labels[i]\n",
    "                \n",
    "                feats = np.vstack((step_3_features, step_2_features, step_1_features))\n",
    "                lbls = np.vstack((step_3_lbls, step_2_lbls, step_1_lbls))\n",
    "                \n",
    "                tree_features_stepped.append(feats)\n",
    "                tree_labels_stepped.append(lbls)\n",
    "                \n",
    "            if len(tree_features_stepped) > 0 and len(tree_labels_stepped) > 0:\n",
    "                tree_features = np.dstack(tree_features_stepped)\n",
    "                features.append(tree_features)\n",
    "\n",
    "                tree_labels = np.dstack(tree_labels_stepped)\n",
    "                labels.append(tree_labels)\n",
    "\n",
    "    return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'det', 'fixed', 'obj', 'obl', 'expl', 'case', 'list', 'aux', 'compound', 'reparandum', 'nummod', 'amod', 'conj', 'goeswith', 'cop', 'xcomp', 'dislocated', 'ccomp', 'flat', 'advmod', 'csubj', 'vocative', 'iobj', 'discourse', 'nsubj', 'punct', 'advcl', 'cc', 'parataxis', 'mark', 'appos', 'root', 'acl', 'nmod'}\n",
      "Features shape (19136, 3, 900)\n",
      "Labels shape (19136, 3, 34)\n",
      "Num classes 34\n",
      "Data preparation finished\n"
     ]
    }
   ],
   "source": [
    "train_labels, train_features = _get_labels_features(files[0])\n",
    "test_labels, test_features = _get_labels_features(files[1])\n",
    "print(set(all_labels))\n",
    "\n",
    "train_features = np.dstack(train_features)\n",
    "test_features = np.dstack(test_features)\n",
    "\n",
    "train_features = np.moveaxis(train_features, -1, 0)\n",
    "test_features = np.moveaxis(test_features, -1, 0)\n",
    "\n",
    "train_labels = np.dstack(train_labels)\n",
    "test_labels = np.dstack(test_labels)\n",
    "\n",
    "train_labels = np.moveaxis(train_labels, -1, 0)\n",
    "test_labels = np.moveaxis(test_labels, -1, 0)\n",
    "\n",
    "print('Features shape {}'.format(train_features.shape))  #(19136, 3, 900)\n",
    "print('Labels shape {}'.format(train_labels.shape))  #(19136, 3, 34)\n",
    "\n",
    "print('Num classes {}'.format(len(all_labels)))\n",
    "print('Data preparation finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "19136/19136 [==============================] - 367s 19ms/step - loss: 0.9060 - precision: 0.8187 - recall: 0.6353 - f1: 0.7068\n",
      "Epoch 2/5\n",
      "19136/19136 [==============================] - 463s 24ms/step - loss: 0.4755 - precision: 0.8888 - recall: 0.8148 - f1: 0.8495\n",
      "Epoch 3/5\n",
      "19136/19136 [==============================] - 431s 23ms/step - loss: 0.3513 - precision: 0.9146 - recall: 0.8666 - f1: 0.8895\n",
      "Epoch 4/5\n",
      "19136/19136 [==============================] - 347s 18ms/step - loss: 0.2873 - precision: 0.9277 - recall: 0.8929 - f1: 0.9096\n",
      "Epoch 5/5\n",
      "19136/19136 [==============================] - 367s 19ms/step - loss: 0.2493 - precision: 0.9358 - recall: 0.9081 - f1: 0.9215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ab4b048>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "timestep = 3\n",
    "dim = 900\n",
    "\n",
    "model.add(LSTM(512, input_shape=(timestep, dim), return_sequences=True))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(TimeDistributed(Dense(256)))\n",
    "\n",
    "model.add(Dense(units=len(all_labels), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[precision, recall, f1])\n",
    "\n",
    "model.fit(train_features, train_labels, epochs=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4326/4326 [==============================] - 5s 1ms/step\n",
      "['loss', 'precision', 'recall', 'f1']\n",
      "[1.2100322953099407, 0.765577699043549, 0.7299275730309859, 0.7472582935074441]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(test_features, test_labels, batch_size=128)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(loss_and_metrics)\n",
    "\n",
    "# ['precision', 'recall',   'f1']\n",
    "# [     0.766,     0.73,   0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
