{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, LSTM, TimeDistributed, Activation\n",
    "import keras_metrics\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cn_file = './data/numberbatch-en-17.06.txt'\n",
    "\n",
    "cn_vectors = KeyedVectors.load_word2vec_format(cn_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_tags(string):\n",
    "    return [tuple(i.split(\"/\")) for i in string.split()]\n",
    "\n",
    "def readTrainData(filename):\n",
    "    data = []\n",
    "    for line in open(filename):\n",
    "        line = line.strip()\n",
    "        #read in training or dev data with labels\n",
    "        if len(line.split('\\t')) == 7:\n",
    "            (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = \\\n",
    "            line.split('\\t')\n",
    "        else:\n",
    "            continue\n",
    "        # ignoring the training data that has middle label \n",
    "        nYes = eval(judge)[0]            \n",
    "        if nYes >= 3:\n",
    "            amt_label = True\n",
    "            data.append((split_tags(origsenttag), split_tags(candsenttag), amt_label))\n",
    "        elif nYes <= 1:\n",
    "            amt_label = False\n",
    "            data.append((split_tags(origsenttag), split_tags(candsenttag), amt_label))\n",
    "    return data\n",
    "\n",
    "def readTestData(filename):\n",
    "    data = []\n",
    "    for line in open(filename):\n",
    "        line = line.strip()\n",
    "        #read in training or dev data with labels\n",
    "        if len(line.split('\\t')) == 7:\n",
    "            (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = \\\n",
    "            line.split('\\t')\n",
    "        else:\n",
    "            continue\n",
    "        # ignoring the training data that has middle label \n",
    "        nYes = int(judge[0])\n",
    "        if nYes >= 4:\n",
    "            expert_label = True\n",
    "        elif nYes <= 2:\n",
    "            expert_label = False\n",
    "        else:\n",
    "            expert_label = None\n",
    "        data.append((split_tags(origsenttag), split_tags(candsenttag), expert_label))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_data = readTrainData(\"./data/data/dev.data\")\n",
    "train_data = readTrainData(\"./data/data/train.data\")\n",
    "test_data = readTestData(\"./data/data/test.data\")\n",
    "\n",
    "len(dev_data)  #4142\n",
    "len(test_data)  #972\n",
    "len(train_data)  #11530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTweetEmbedding(tweet):\n",
    "    word_vectors = []\n",
    "    exceptions = 0\n",
    "    for word in tweet:\n",
    "        try:\n",
    "            word_vector = cn_vectors.get_vector(word[0].lower())\n",
    "        except:\n",
    "            continue\n",
    "        word_vectors.append(word_vector)\n",
    "        \n",
    "        \n",
    "    return np.mean(np.array(word_vectors), axis=0), exceptions\n",
    "\n",
    "\n",
    "def getLabel(label):\n",
    "    if label == True:\n",
    "        return 1\n",
    "    if label == False:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def getLabelsFeatures(data, is_train):\n",
    "    labels, features = [], []\n",
    "    for row in data:\n",
    "        lbl = getLabel(row[2])\n",
    "        if lbl is None and is_train:\n",
    "            continue\n",
    "        labels.append(lbl)\n",
    "        original_embedding, _ = getTweetEmbedding(row[0])\n",
    "        cand_embedding, _ = getTweetEmbedding(row[1])\n",
    "        embedding = np.hstack([original_embedding, cand_embedding])\n",
    "#         embedding = np.mean( np.array([ original_embedding, cand_embedding ]), axis=0 )\n",
    "        features.append(embedding)\n",
    "    return labels, features\n",
    "    \n",
    "    \n",
    "dev_labels, dev_features = getLabelsFeatures(dev_data, is_train=True)\n",
    "test_labels, test_features = getLabelsFeatures(test_data, is_train=False)\n",
    "train_labels, train_features = getLabelsFeatures(train_data, is_train=True)\n",
    "\n",
    "\n",
    "dev_features = np.array(dev_features)\n",
    "dev_labels = np.array(dev_labels)\n",
    "\n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** KERAS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "11530/11530 [==============================] - 21s 2ms/step - loss: 0.5376 - precision: 0.6097 - recall: 0.4632 - f1: 0.4887\n",
      "Epoch 2/15\n",
      "11530/11530 [==============================] - 15s 1ms/step - loss: 0.4601 - precision: 0.7298 - recall: 0.5879 - f1: 0.6162\n",
      "Epoch 3/15\n",
      "11530/11530 [==============================] - 14s 1ms/step - loss: 0.4281 - precision: 0.7585 - recall: 0.6276 - f1: 0.6537\n",
      "Epoch 4/15\n",
      "11530/11530 [==============================] - 19s 2ms/step - loss: 0.4033 - precision: 0.7757 - recall: 0.6558 - f1: 0.6804\n",
      "Epoch 5/15\n",
      "11530/11530 [==============================] - 20s 2ms/step - loss: 0.3782 - precision: 0.7854 - recall: 0.6659 - f1: 0.6889\n",
      "Epoch 6/15\n",
      "11530/11530 [==============================] - 18s 2ms/step - loss: 0.3596 - precision: 0.7953 - recall: 0.6938 - f1: 0.7123\n",
      "Epoch 7/15\n",
      "11530/11530 [==============================] - 13s 1ms/step - loss: 0.3408 - precision: 0.8089 - recall: 0.7174 - f1: 0.7322\n",
      "Epoch 8/15\n",
      "11530/11530 [==============================] - 11s 980us/step - loss: 0.3206 - precision: 0.8207 - recall: 0.7412 - f1: 0.7526\n",
      "Epoch 9/15\n",
      "11530/11530 [==============================] - 13s 1ms/step - loss: 0.3082 - precision: 0.8266 - recall: 0.7487 - f1: 0.7595\n",
      "Epoch 10/15\n",
      "11530/11530 [==============================] - 10s 910us/step - loss: 0.2976 - precision: 0.8326 - recall: 0.7648 - f1: 0.7710\n",
      "Epoch 11/15\n",
      "11530/11530 [==============================] - 11s 939us/step - loss: 0.2819 - precision: 0.8371 - recall: 0.7821 - f1: 0.7853\n",
      "Epoch 12/15\n",
      "11530/11530 [==============================] - 10s 856us/step - loss: 0.2684 - precision: 0.8436 - recall: 0.7897 - f1: 0.7926\n",
      "Epoch 13/15\n",
      "11530/11530 [==============================] - 13s 1ms/step - loss: 0.2601 - precision: 0.8468 - recall: 0.7913 - f1: 0.7953\n",
      "Epoch 14/15\n",
      "11530/11530 [==============================] - 10s 873us/step - loss: 0.2487 - precision: 0.8570 - recall: 0.8123 - f1: 0.8127\n",
      "Epoch 15/15\n",
      "11530/11530 [==============================] - 14s 1ms/step - loss: 0.2370 - precision: 0.8585 - recall: 0.8174 - f1: 0.8160\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, activation='relu', input_dim=600))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[precision, recall, f1])\n",
    "\n",
    "loss_and_metrics = model.fit(train_features, train_labels, epochs=15, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_features)\n",
    "# 838\tNN\t01_NN\t\tF: 0.187\tPrec: 0.367\tRec: 0.126\t\tP-corr: 0.243\tF1: 0.474\tPrec: 0.359\tRec: 0.697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\t0.1048\n",
      "false\t0.3941\n",
      "false\t0.3416\n",
      "false\t0.1153\n",
      "false\t0.1297\n",
      "false\t0.0537\n",
      "false\t0.0212\n",
      "false\t0.0019\n",
      "false\t0.2166\n",
      "false\t0.0395\n",
      "false\t0.0625\n",
      "false\t0.0555\n",
      "false\t0.2247\n",
      "false\t0.2813\n",
      "false\t0.1304\n",
      "false\t0.2944\n",
      "false\t0.3915\n",
      "false\t0.2937\n",
      "false\t0.0395\n",
      "false\t0.0229\n",
      "false\t0.2479\n",
      "false\t0.0362\n",
      "false\t0.0055\n",
      "false\t0.0382\n",
      "false\t0.2472\n",
      "false\t0.1595\n",
      "false\t0.1090\n",
      "false\t0.1711\n",
      "false\t0.2444\n",
      "false\t0.1628\n",
      "false\t0.4621\n",
      "false\t0.1802\n",
      "false\t0.2154\n",
      "false\t0.0358\n",
      "false\t0.4613\n",
      "true\t0.7293\n",
      "true\t0.5815\n",
      "false\t0.2997\n",
      "false\t0.0845\n",
      "true\t0.5767\n",
      "false\t0.0054\n",
      "false\t0.0451\n",
      "false\t0.0043\n",
      "false\t0.2309\n",
      "false\t0.0507\n",
      "false\t0.4869\n",
      "false\t0.0149\n",
      "false\t0.3491\n",
      "false\t0.2091\n",
      "false\t0.0024\n",
      "true\t0.5009\n",
      "false\t0.0151\n",
      "false\t0.2797\n",
      "false\t0.1103\n",
      "true\t0.7150\n",
      "false\t0.4747\n",
      "false\t0.0569\n",
      "false\t0.4042\n",
      "false\t0.1492\n",
      "false\t0.4496\n",
      "false\t0.0283\n",
      "false\t0.0044\n",
      "false\t0.0002\n",
      "false\t0.0067\n",
      "false\t0.0010\n",
      "false\t0.0046\n",
      "false\t0.0056\n",
      "false\t0.0017\n",
      "false\t0.0303\n",
      "false\t0.0187\n",
      "false\t0.0000\n",
      "false\t0.0243\n",
      "false\t0.0077\n",
      "false\t0.0145\n",
      "false\t0.0198\n",
      "false\t0.0128\n",
      "false\t0.0029\n",
      "false\t0.0000\n",
      "false\t0.0042\n",
      "false\t0.0626\n",
      "false\t0.0009\n",
      "false\t0.0310\n",
      "false\t0.0169\n",
      "false\t0.0364\n",
      "false\t0.1437\n",
      "false\t0.0804\n",
      "false\t0.0686\n",
      "false\t0.1967\n",
      "false\t0.0108\n",
      "false\t0.2890\n",
      "false\t0.0001\n",
      "false\t0.0077\n",
      "false\t0.0002\n",
      "false\t0.4801\n",
      "true\t0.6228\n",
      "false\t0.1008\n",
      "false\t0.0646\n",
      "false\t0.0743\n",
      "true\t0.5249\n",
      "false\t0.0621\n",
      "false\t0.3113\n",
      "false\t0.0560\n",
      "false\t0.2047\n",
      "false\t0.0136\n",
      "false\t0.0760\n",
      "false\t0.0241\n",
      "false\t0.4385\n",
      "true\t0.5046\n",
      "false\t0.0007\n",
      "false\t0.0155\n",
      "true\t0.5707\n",
      "false\t0.2402\n",
      "true\t0.6704\n",
      "true\t0.6171\n",
      "false\t0.0394\n",
      "false\t0.0030\n",
      "false\t0.0071\n",
      "false\t0.0796\n",
      "false\t0.0072\n",
      "false\t0.2853\n",
      "false\t0.1251\n",
      "false\t0.0242\n",
      "false\t0.2208\n",
      "false\t0.2842\n",
      "false\t0.0007\n",
      "false\t0.0000\n",
      "false\t0.0002\n",
      "false\t0.0019\n",
      "false\t0.0000\n",
      "false\t0.0009\n",
      "false\t0.0001\n",
      "false\t0.0072\n",
      "false\t0.0000\n",
      "false\t0.0042\n",
      "false\t0.0594\n",
      "false\t0.0178\n",
      "false\t0.0068\n",
      "false\t0.0116\n",
      "false\t0.0011\n",
      "false\t0.0082\n",
      "false\t0.0011\n",
      "false\t0.0006\n",
      "false\t0.0017\n",
      "false\t0.0014\n",
      "false\t0.0000\n",
      "false\t0.0131\n",
      "false\t0.0008\n",
      "false\t0.0001\n",
      "false\t0.0455\n",
      "false\t0.0026\n",
      "false\t0.1379\n",
      "false\t0.0907\n",
      "false\t0.4568\n",
      "false\t0.0173\n",
      "false\t0.1777\n",
      "false\t0.1398\n",
      "false\t0.2403\n",
      "false\t0.0194\n",
      "true\t0.7406\n",
      "true\t0.5023\n",
      "false\t0.0008\n",
      "true\t0.7949\n",
      "false\t0.1942\n",
      "false\t0.0679\n",
      "false\t0.0551\n",
      "false\t0.4121\n",
      "false\t0.0444\n",
      "false\t0.3111\n",
      "false\t0.2429\n",
      "false\t0.1050\n",
      "false\t0.0666\n",
      "false\t0.0290\n",
      "false\t0.0531\n",
      "false\t0.0538\n",
      "false\t0.3437\n",
      "false\t0.0921\n",
      "false\t0.1255\n",
      "false\t0.0042\n",
      "false\t0.0015\n",
      "false\t0.0248\n",
      "false\t0.2158\n",
      "false\t0.3311\n",
      "false\t0.0029\n",
      "false\t0.0159\n",
      "false\t0.0003\n",
      "false\t0.0113\n",
      "false\t0.0164\n",
      "false\t0.0950\n",
      "false\t0.0268\n",
      "false\t0.1918\n",
      "false\t0.1081\n",
      "false\t0.3207\n",
      "false\t0.3909\n",
      "false\t0.0175\n",
      "false\t0.0201\n",
      "false\t0.0020\n",
      "false\t0.3166\n",
      "false\t0.0026\n",
      "true\t0.8231\n",
      "false\t0.0401\n",
      "false\t0.0287\n",
      "false\t0.1563\n",
      "false\t0.0048\n",
      "false\t0.0240\n",
      "false\t0.0026\n",
      "false\t0.0122\n",
      "false\t0.0803\n",
      "false\t0.0552\n",
      "false\t0.0332\n",
      "false\t0.0047\n",
      "false\t0.0021\n",
      "false\t0.2536\n",
      "false\t0.1172\n",
      "false\t0.0911\n",
      "false\t0.0850\n",
      "false\t0.0017\n",
      "false\t0.0000\n",
      "false\t0.0004\n",
      "false\t0.0003\n",
      "false\t0.0014\n",
      "false\t0.0003\n",
      "false\t0.0721\n",
      "false\t0.0442\n",
      "false\t0.2438\n",
      "false\t0.0330\n",
      "false\t0.1124\n",
      "false\t0.1835\n",
      "false\t0.3545\n",
      "false\t0.2535\n",
      "false\t0.1118\n",
      "false\t0.0076\n",
      "false\t0.1377\n",
      "false\t0.0995\n",
      "false\t0.3602\n",
      "false\t0.3311\n",
      "false\t0.4946\n",
      "false\t0.0071\n",
      "false\t0.0682\n",
      "false\t0.0528\n",
      "false\t0.0284\n",
      "false\t0.4928\n",
      "false\t0.0183\n",
      "false\t0.0036\n",
      "false\t0.0035\n",
      "false\t0.0820\n",
      "false\t0.0399\n",
      "false\t0.0016\n",
      "false\t0.2837\n",
      "false\t0.0036\n",
      "false\t0.3578\n",
      "true\t0.7859\n",
      "false\t0.0185\n",
      "false\t0.3999\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0074\n",
      "false\t0.0699\n",
      "false\t0.2539\n",
      "false\t0.1212\n",
      "false\t0.3325\n",
      "false\t0.0021\n",
      "false\t0.0807\n",
      "false\t0.2181\n",
      "false\t0.0016\n",
      "false\t0.0019\n",
      "false\t0.0383\n",
      "false\t0.1035\n",
      "false\t0.0002\n",
      "false\t0.0087\n",
      "false\t0.0005\n",
      "false\t0.0403\n",
      "false\t0.0394\n",
      "false\t0.0009\n",
      "false\t0.0074\n",
      "false\t0.0135\n",
      "false\t0.0080\n",
      "false\t0.0573\n",
      "false\t0.0942\n",
      "false\t0.0998\n",
      "false\t0.3541\n",
      "false\t0.0000\n",
      "false\t0.0171\n",
      "false\t0.0005\n",
      "false\t0.0002\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0002\n",
      "false\t0.0003\n",
      "false\t0.0001\n",
      "false\t0.0009\n",
      "false\t0.0132\n",
      "false\t0.0177\n",
      "false\t0.0002\n",
      "false\t0.0068\n",
      "false\t0.0006\n",
      "false\t0.0478\n",
      "false\t0.0275\n",
      "false\t0.1146\n",
      "false\t0.0056\n",
      "false\t0.1236\n",
      "false\t0.1452\n",
      "false\t0.4773\n",
      "false\t0.0732\n",
      "false\t0.0128\n",
      "false\t0.0378\n",
      "false\t0.0005\n",
      "false\t0.0142\n",
      "false\t0.0410\n",
      "false\t0.0092\n",
      "false\t0.2271\n",
      "false\t0.0301\n",
      "false\t0.1031\n",
      "false\t0.0110\n",
      "false\t0.1109\n",
      "false\t0.3610\n",
      "false\t0.3927\n",
      "true\t0.7733\n",
      "true\t0.7931\n",
      "false\t0.1458\n",
      "false\t0.0194\n",
      "false\t0.1026\n",
      "true\t0.5490\n",
      "true\t0.6185\n",
      "false\t0.2380\n",
      "false\t0.0559\n",
      "false\t0.3078\n",
      "false\t0.1298\n",
      "false\t0.4016\n",
      "false\t0.1067\n",
      "false\t0.1751\n",
      "false\t0.3570\n",
      "true\t0.9365\n",
      "true\t0.5475\n",
      "true\t0.6823\n",
      "false\t0.0271\n",
      "true\t0.7313\n",
      "false\t0.2574\n",
      "false\t0.0476\n",
      "true\t0.7440\n",
      "false\t0.3345\n",
      "false\t0.3670\n",
      "false\t0.0865\n",
      "false\t0.0008\n",
      "false\t0.0114\n",
      "false\t0.0011\n",
      "false\t0.0006\n",
      "false\t0.0058\n",
      "false\t0.0093\n",
      "false\t0.0052\n",
      "false\t0.0144\n",
      "false\t0.0001\n",
      "false\t0.0134\n",
      "false\t0.0008\n",
      "false\t0.0002\n",
      "false\t0.0004\n",
      "false\t0.0038\n",
      "false\t0.0082\n",
      "false\t0.0939\n",
      "false\t0.0004\n",
      "false\t0.0501\n",
      "false\t0.0020\n",
      "false\t0.1431\n",
      "false\t0.0658\n",
      "false\t0.0960\n",
      "false\t0.2348\n",
      "true\t0.5711\n",
      "false\t0.2969\n",
      "false\t0.1897\n",
      "false\t0.3919\n",
      "false\t0.3551\n",
      "false\t0.1208\n",
      "false\t0.0449\n",
      "false\t0.1392\n",
      "false\t0.2232\n",
      "false\t0.2249\n",
      "false\t0.2274\n",
      "false\t0.0810\n",
      "false\t0.1142\n",
      "false\t0.0468\n",
      "false\t0.4219\n",
      "false\t0.3836\n",
      "false\t0.4331\n",
      "false\t0.1141\n",
      "true\t0.5083\n",
      "false\t0.0473\n",
      "false\t0.1089\n",
      "false\t0.0695\n",
      "false\t0.0257\n",
      "false\t0.2539\n",
      "false\t0.2908\n",
      "false\t0.1381\n",
      "false\t0.3496\n",
      "false\t0.1239\n",
      "true\t0.5827\n",
      "true\t0.6013\n",
      "false\t0.4321\n",
      "false\t0.2526\n",
      "true\t0.8666\n",
      "false\t0.4025\n",
      "false\t0.0342\n",
      "false\t0.3274\n",
      "false\t0.0389\n",
      "false\t0.4305\n",
      "false\t0.3852\n",
      "false\t0.0938\n",
      "false\t0.2892\n",
      "false\t0.1855\n",
      "false\t0.2246\n",
      "false\t0.0175\n",
      "false\t0.0015\n",
      "false\t0.0008\n",
      "false\t0.1238\n",
      "false\t0.0000\n",
      "false\t0.0020\n",
      "true\t0.7262\n",
      "false\t0.1688\n",
      "false\t0.0183\n",
      "false\t0.0622\n",
      "false\t0.0622\n",
      "false\t0.0389\n",
      "false\t0.0875\n",
      "false\t0.2714\n",
      "false\t0.0723\n",
      "false\t0.1366\n",
      "false\t0.0101\n",
      "false\t0.1200\n",
      "false\t0.0032\n",
      "false\t0.0215\n",
      "false\t0.0177\n",
      "false\t0.2076\n",
      "false\t0.2050\n",
      "false\t0.1084\n",
      "true\t0.5670\n",
      "false\t0.0109\n",
      "false\t0.0145\n",
      "false\t0.0013\n",
      "false\t0.0095\n",
      "false\t0.0000\n",
      "false\t0.0001\n",
      "false\t0.1086\n",
      "false\t0.0308\n",
      "false\t0.0022\n",
      "false\t0.0000\n",
      "false\t0.0514\n",
      "false\t0.1606\n",
      "false\t0.0319\n",
      "false\t0.0807\n",
      "false\t0.0443\n",
      "false\t0.0083\n",
      "false\t0.2393\n",
      "false\t0.0200\n",
      "false\t0.0003\n",
      "false\t0.0055\n",
      "false\t0.0166\n",
      "false\t0.0061\n",
      "false\t0.0015\n",
      "false\t0.0142\n",
      "false\t0.1564\n",
      "false\t0.0107\n",
      "false\t0.0328\n",
      "false\t0.2318\n",
      "true\t0.5204\n",
      "false\t0.2066\n",
      "false\t0.0783\n",
      "false\t0.0257\n",
      "false\t0.1933\n",
      "false\t0.0777\n",
      "false\t0.0057\n",
      "false\t0.0302\n",
      "false\t0.2791\n",
      "false\t0.1266\n",
      "false\t0.0001\n",
      "false\t0.4684\n",
      "false\t0.2432\n",
      "false\t0.0457\n",
      "false\t0.0231\n",
      "false\t0.0013\n",
      "false\t0.0264\n",
      "false\t0.0086\n",
      "false\t0.4613\n",
      "false\t0.0464\n",
      "false\t0.0284\n",
      "false\t0.0588\n",
      "false\t0.3226\n",
      "false\t0.0421\n",
      "false\t0.0429\n",
      "false\t0.0701\n",
      "false\t0.2421\n",
      "false\t0.0086\n",
      "false\t0.1254\n",
      "false\t0.0118\n",
      "false\t0.0402\n",
      "false\t0.2203\n",
      "false\t0.0566\n",
      "false\t0.1030\n",
      "false\t0.1208\n",
      "false\t0.0001\n",
      "false\t0.0084\n",
      "false\t0.0227\n",
      "false\t0.0214\n",
      "false\t0.0073\n",
      "false\t0.1862\n",
      "false\t0.0260\n",
      "false\t0.0000\n",
      "false\t0.0562\n",
      "false\t0.0037\n",
      "false\t0.2576\n",
      "false\t0.0032\n",
      "false\t0.0011\n",
      "false\t0.0020\n",
      "false\t0.0201\n",
      "false\t0.0177\n",
      "false\t0.0391\n",
      "false\t0.0098\n",
      "false\t0.0284\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0222\n",
      "false\t0.0017\n",
      "false\t0.0008\n",
      "false\t0.0002\n",
      "false\t0.0000\n",
      "false\t0.0021\n",
      "false\t0.0000\n",
      "false\t0.0058\n",
      "false\t0.0005\n",
      "false\t0.0089\n",
      "false\t0.0156\n",
      "false\t0.0306\n",
      "false\t0.0087\n",
      "false\t0.0342\n",
      "false\t0.2516\n",
      "false\t0.0974\n",
      "false\t0.2323\n",
      "false\t0.4554\n",
      "false\t0.1671\n",
      "false\t0.2262\n",
      "false\t0.1149\n",
      "false\t0.1578\n",
      "false\t0.3208\n",
      "false\t0.2632\n",
      "false\t0.2290\n",
      "false\t0.2121\n",
      "false\t0.2722\n",
      "false\t0.1876\n",
      "false\t0.4099\n",
      "false\t0.2294\n",
      "false\t0.1368\n",
      "true\t0.7682\n",
      "false\t0.1683\n",
      "false\t0.0766\n",
      "false\t0.1859\n",
      "false\t0.1541\n",
      "false\t0.3940\n",
      "true\t0.5772\n",
      "true\t0.5099\n",
      "false\t0.0972\n",
      "false\t0.0041\n",
      "true\t0.6123\n",
      "false\t0.1434\n",
      "false\t0.2685\n",
      "false\t0.1215\n",
      "false\t0.0309\n",
      "false\t0.1161\n",
      "true\t0.6989\n",
      "false\t0.4215\n",
      "false\t0.0184\n",
      "false\t0.1585\n",
      "false\t0.4807\n",
      "false\t0.1704\n",
      "false\t0.1989\n",
      "false\t0.2880\n",
      "false\t0.2550\n",
      "false\t0.0248\n",
      "false\t0.2440\n",
      "false\t0.0153\n",
      "false\t0.1169\n",
      "false\t0.4009\n",
      "false\t0.3056\n",
      "false\t0.1759\n",
      "false\t0.4131\n",
      "false\t0.1430\n",
      "false\t0.2546\n",
      "true\t0.7301\n",
      "true\t0.9359\n",
      "true\t0.8983\n",
      "true\t0.9664\n",
      "false\t0.2829\n",
      "false\t0.0311\n",
      "false\t0.1397\n",
      "false\t0.1891\n",
      "false\t0.0011\n",
      "false\t0.1041\n",
      "false\t0.3315\n",
      "false\t0.0033\n",
      "false\t0.3099\n",
      "false\t0.0445\n",
      "false\t0.0079\n",
      "false\t0.0469\n",
      "false\t0.0182\n",
      "true\t0.8904\n",
      "false\t0.1134\n",
      "false\t0.4019\n",
      "true\t0.9960\n",
      "false\t0.2309\n",
      "false\t0.0152\n",
      "false\t0.0023\n",
      "false\t0.0259\n",
      "false\t0.0000\n",
      "false\t0.0001\n",
      "false\t0.0014\n",
      "false\t0.0013\n",
      "false\t0.0028\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0058\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0112\n",
      "false\t0.0049\n",
      "false\t0.0089\n",
      "false\t0.0054\n",
      "true\t0.8454\n",
      "false\t0.0373\n",
      "false\t0.2056\n",
      "false\t0.3870\n",
      "false\t0.1650\n",
      "true\t0.8024\n",
      "false\t0.0180\n",
      "false\t0.0147\n",
      "false\t0.0450\n",
      "false\t0.2360\n",
      "false\t0.0226\n",
      "false\t0.1030\n",
      "false\t0.0664\n",
      "true\t0.9585\n",
      "false\t0.1613\n",
      "true\t0.7252\n",
      "false\t0.0718\n",
      "false\t0.0342\n",
      "false\t0.0033\n",
      "false\t0.0069\n",
      "false\t0.1304\n",
      "false\t0.0777\n",
      "true\t0.7565\n",
      "false\t0.0003\n",
      "false\t0.0092\n",
      "true\t0.5540\n",
      "false\t0.0821\n",
      "false\t0.4174\n",
      "false\t0.0588\n",
      "false\t0.3720\n",
      "true\t0.7165\n",
      "true\t0.5604\n",
      "false\t0.0961\n",
      "false\t0.0681\n",
      "false\t0.1698\n",
      "false\t0.0121\n",
      "true\t0.8523\n",
      "true\t0.5572\n",
      "false\t0.0039\n",
      "false\t0.1427\n",
      "false\t0.0001\n",
      "false\t0.0704\n",
      "false\t0.0509\n",
      "false\t0.1664\n",
      "false\t0.3909\n",
      "false\t0.1341\n",
      "true\t0.5914\n",
      "true\t0.9130\n",
      "true\t0.6189\n",
      "false\t0.3820\n",
      "true\t0.7139\n",
      "false\t0.1219\n",
      "false\t0.0029\n",
      "false\t0.2183\n",
      "false\t0.2493\n",
      "false\t0.0257\n",
      "false\t0.2995\n",
      "true\t0.7631\n",
      "true\t0.6084\n",
      "false\t0.1895\n",
      "false\t0.0015\n",
      "false\t0.1328\n",
      "false\t0.1656\n",
      "false\t0.0818\n",
      "false\t0.0895\n",
      "false\t0.1451\n",
      "false\t0.2366\n",
      "false\t0.2916\n",
      "false\t0.2207\n",
      "false\t0.0345\n",
      "false\t0.0123\n",
      "false\t0.2675\n",
      "false\t0.1274\n",
      "false\t0.1673\n",
      "false\t0.4058\n",
      "false\t0.1686\n",
      "false\t0.0940\n",
      "false\t0.0006\n",
      "false\t0.0112\n",
      "false\t0.2076\n",
      "false\t0.0137\n",
      "true\t0.5986\n",
      "false\t0.0954\n",
      "false\t0.0757\n",
      "false\t0.0033\n",
      "false\t0.2834\n",
      "false\t0.0007\n",
      "false\t0.0060\n",
      "false\t0.0529\n",
      "false\t0.0036\n",
      "false\t0.4673\n",
      "false\t0.0002\n",
      "false\t0.0208\n",
      "false\t0.0002\n",
      "false\t0.0001\n",
      "false\t0.0000\n",
      "false\t0.0117\n",
      "false\t0.0632\n",
      "false\t0.0124\n",
      "false\t0.0065\n",
      "false\t0.0045\n",
      "true\t0.5051\n",
      "false\t0.3033\n",
      "false\t0.2683\n",
      "false\t0.0532\n",
      "false\t0.1518\n",
      "false\t0.0314\n",
      "false\t0.0167\n",
      "false\t0.3419\n",
      "false\t0.0255\n",
      "false\t0.3899\n",
      "false\t0.0002\n",
      "false\t0.0930\n",
      "false\t0.1311\n",
      "false\t0.0603\n",
      "false\t0.2152\n",
      "false\t0.2642\n",
      "false\t0.0620\n",
      "false\t0.1294\n",
      "true\t0.5612\n",
      "false\t0.4153\n",
      "false\t0.0898\n",
      "false\t0.4938\n",
      "false\t0.4181\n",
      "false\t0.4644\n",
      "true\t0.5919\n",
      "false\t0.1376\n",
      "false\t0.0137\n",
      "false\t0.0172\n",
      "false\t0.1660\n",
      "false\t0.0073\n",
      "false\t0.0001\n",
      "false\t0.1483\n",
      "false\t0.1923\n",
      "false\t0.3523\n",
      "false\t0.1918\n",
      "false\t0.0002\n",
      "false\t0.0062\n",
      "false\t0.0658\n",
      "false\t0.0434\n",
      "false\t0.0030\n",
      "false\t0.1201\n",
      "false\t0.0911\n",
      "false\t0.0008\n",
      "false\t0.0003\n",
      "false\t0.0000\n",
      "false\t0.2012\n",
      "true\t0.5885\n",
      "false\t0.0623\n",
      "false\t0.0203\n",
      "false\t0.0021\n",
      "false\t0.0001\n",
      "false\t0.1972\n",
      "false\t0.0198\n",
      "false\t0.1374\n",
      "false\t0.0154\n",
      "false\t0.0012\n",
      "false\t0.0915\n",
      "false\t0.0009\n",
      "false\t0.0336\n",
      "false\t0.0027\n",
      "false\t0.0000\n",
      "false\t0.0009\n",
      "false\t0.0000\n",
      "false\t0.0042\n",
      "false\t0.0708\n",
      "false\t0.0159\n",
      "false\t0.0021\n",
      "false\t0.0287\n",
      "false\t0.0193\n",
      "false\t0.0004\n",
      "false\t0.0088\n",
      "false\t0.0005\n",
      "false\t0.0119\n",
      "false\t0.0248\n",
      "false\t0.0000\n",
      "false\t0.0127\n",
      "false\t0.0531\n",
      "false\t0.0741\n",
      "false\t0.0119\n",
      "false\t0.0002\n",
      "false\t0.3143\n",
      "false\t0.0770\n",
      "false\t0.0394\n",
      "false\t0.1848\n",
      "false\t0.0127\n",
      "false\t0.0103\n",
      "false\t0.0370\n",
      "false\t0.1680\n",
      "false\t0.0043\n",
      "false\t0.4476\n",
      "false\t0.0049\n",
      "false\t0.0559\n",
      "false\t0.0000\n",
      "false\t0.0020\n",
      "false\t0.0009\n",
      "false\t0.0006\n",
      "false\t0.2649\n",
      "false\t0.1596\n",
      "false\t0.1770\n",
      "false\t0.1780\n",
      "false\t0.0000\n",
      "false\t0.0002\n",
      "false\t0.0000\n",
      "false\t0.0023\n",
      "false\t0.4974\n",
      "false\t0.1775\n",
      "false\t0.4068\n",
      "true\t0.5774\n",
      "false\t0.0115\n",
      "false\t0.3031\n",
      "false\t0.1738\n",
      "false\t0.0311\n",
      "false\t0.4411\n",
      "false\t0.2606\n",
      "false\t0.4397\n",
      "false\t0.0012\n",
      "false\t0.0004\n",
      "false\t0.0754\n",
      "false\t0.3413\n",
      "false\t0.3584\n",
      "false\t0.0905\n",
      "false\t0.0241\n",
      "false\t0.0039\n",
      "false\t0.2425\n",
      "false\t0.2244\n",
      "false\t0.1792\n",
      "false\t0.0050\n",
      "false\t0.1517\n",
      "false\t0.0005\n",
      "false\t0.0000\n",
      "false\t0.2672\n",
      "false\t0.0031\n",
      "false\t0.0507\n",
      "false\t0.2411\n",
      "false\t0.2589\n",
      "false\t0.0799\n",
      "false\t0.1580\n",
      "false\t0.0319\n",
      "false\t0.0983\n",
      "false\t0.0157\n",
      "false\t0.3505\n",
      "false\t0.1960\n",
      "false\t0.1888\n",
      "false\t0.0037\n",
      "false\t0.0000\n",
      "false\t0.0013\n",
      "false\t0.0001\n",
      "false\t0.0212\n",
      "false\t0.0330\n",
      "false\t0.0098\n",
      "false\t0.0001\n",
      "false\t0.0010\n",
      "false\t0.0082\n",
      "false\t0.0000\n",
      "false\t0.0040\n",
      "false\t0.1068\n",
      "false\t0.0136\n",
      "false\t0.0005\n",
      "false\t0.0003\n",
      "false\t0.0190\n",
      "false\t0.0263\n",
      "false\t0.0064\n",
      "false\t0.0098\n",
      "false\t0.0000\n",
      "false\t0.0118\n",
      "false\t0.0036\n",
      "false\t0.0002\n",
      "false\t0.0000\n",
      "false\t0.0313\n",
      "false\t0.0030\n",
      "false\t0.1585\n",
      "false\t0.0003\n",
      "false\t0.0394\n",
      "false\t0.0047\n",
      "false\t0.0002\n",
      "false\t0.3427\n",
      "false\t0.0674\n",
      "false\t0.0009\n",
      "false\t0.0430\n",
      "false\t0.0005\n",
      "false\t0.0004\n",
      "false\t0.0262\n",
      "false\t0.1899\n",
      "false\t0.1390\n",
      "false\t0.0569\n",
      "false\t0.0304\n",
      "false\t0.0056\n",
      "false\t0.0013\n",
      "false\t0.0001\n",
      "false\t0.0000\n",
      "false\t0.0940\n",
      "false\t0.1621\n",
      "false\t0.0142\n",
      "false\t0.0078\n",
      "false\t0.0149\n",
      "false\t0.0097\n",
      "false\t0.0029\n",
      "false\t0.0035\n",
      "true\t0.5948\n",
      "false\t0.0481\n",
      "false\t0.0724\n",
      "false\t0.0047\n",
      "false\t0.1934\n",
      "false\t0.0104\n",
      "false\t0.0476\n",
      "false\t0.0043\n",
      "false\t0.0547\n",
      "false\t0.0178\n",
      "false\t0.0024\n",
      "false\t0.0040\n",
      "false\t0.0524\n",
      "false\t0.0069\n",
      "false\t0.0016\n",
      "false\t0.0004\n",
      "false\t0.0001\n",
      "false\t0.0002\n",
      "false\t0.0000\n",
      "true\t0.9198\n",
      "false\t0.0002\n",
      "false\t0.0002\n",
      "true\t0.9989\n",
      "false\t0.0004\n",
      "false\t0.0506\n",
      "false\t0.0038\n",
      "false\t0.0014\n",
      "false\t0.0886\n",
      "false\t0.2958\n",
      "false\t0.0002\n",
      "false\t0.0389\n",
      "false\t0.0682\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.1014\n",
      "true\t0.9986\n",
      "false\t0.0087\n",
      "false\t0.0225\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0000\n",
      "false\t0.0000\n"
     ]
    }
   ],
   "source": [
    "for prediction in predictions:\n",
    "    if prediction >= 0.5:\n",
    "        print('true\\t' + \"{0:.4f}\".format(prediction[0]))\n",
    "    else:\n",
    "        print('false\\t' + \"{0:.4f}\".format(prediction[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Simple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.6s finished\n",
      "/Users/rayanral/PycharmProjects/prj-nlp-2019/venv/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/rayanral/PycharmProjects/prj-nlp-2019/venv/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/rayanral/PycharmProjects/prj-nlp-2019/venv/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.37244797, 0.23569798, 0.24670196]),\n",
       " 'score_time': array([0.06008506, 0.04628825, 0.05297589]),\n",
       " 'test_recall_macro': array([0.53647537, 0.54443422, 0.54877727]),\n",
       " 'train_recall_macro': array([0.79515739, 0.82334564, 0.81762384]),\n",
       " 'test_precision_macro': array([0.6564221 , 0.73152672, 0.62282497]),\n",
       " 'train_precision_macro': array([0.89771725, 0.91086276, 0.90454305]),\n",
       " 'test_f1_macro': array([0.48572014, 0.49196107, 0.51983695]),\n",
       " 'train_f1_macro': array([0.82049802, 0.84815443, 0.8420174 ])}"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# clf = DecisionTreeClassifier(max_depth=10)\n",
    "# 'test_f1_macro': array([0.56202534, 0.5483129 , 0.53597202])\n",
    "# 838\tNN\t01_NN\t\tF: 0.182\tPrec: 0.203\tRec: 0.166\t\tP-corr: -0.028\tF1: 0.367\tPrec: 0.240\tRec: 0.783\n",
    "\n",
    "# clf = RandomForestClassifier(max_depth=10, n_estimators=15, max_features=3)\n",
    "#''test_f1_macro': array([0.48649772, 0.48084575, 0.52552964])\n",
    "\n",
    "# clf = SVC(gamma='auto', random_state=42)\n",
    "#  'test_f1_macro': array([0.39521712, 0.39518414, 0.39518414])\n",
    "# 838\tNN\t01_NN\t\tF: 0.151\tPrec: 0.250\tRec: 0.109\t\tP-corr: 0.201\tF1: 0.415\tPrec: 0.279\tRec: 0.806\n",
    "\n",
    "# cross_validate(clf, train_features, train_labels, scoring=['recall_macro', 'precision_macro', 'f1_macro'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(gamma='auto', random_state=42, probability=True)\n",
    "clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\t0.4227\n",
      "false\t0.4501\n",
      "false\t0.4406\n",
      "false\t0.2478\n",
      "false\t0.1347\n",
      "false\t0.3678\n",
      "false\t0.2213\n",
      "false\t0.1741\n",
      "false\t0.3960\n",
      "false\t0.3064\n",
      "false\t0.2803\n",
      "false\t0.2698\n",
      "false\t0.1146\n",
      "false\t0.1217\n",
      "false\t0.3726\n",
      "false\t0.3278\n",
      "false\t0.3781\n",
      "false\t0.3391\n",
      "false\t0.2054\n",
      "false\t0.2458\n",
      "false\t0.3384\n",
      "false\t0.3809\n",
      "false\t0.4179\n",
      "false\t0.3610\n",
      "false\t0.2467\n",
      "false\t0.2587\n",
      "false\t0.2469\n",
      "false\t0.4130\n",
      "false\t0.4522\n",
      "false\t0.3581\n",
      "false\t0.4549\n",
      "false\t0.4230\n",
      "false\t0.4189\n",
      "false\t0.3695\n",
      "false\t0.3845\n",
      "false\t0.3625\n",
      "false\t0.3668\n",
      "false\t0.2481\n",
      "false\t0.2310\n",
      "false\t0.3405\n",
      "false\t0.4246\n",
      "false\t0.1977\n",
      "false\t0.2661\n",
      "false\t0.3361\n",
      "false\t0.1950\n",
      "false\t0.4566\n",
      "false\t0.4731\n",
      "true\t0.5203\n",
      "true\t0.6701\n",
      "true\t0.5186\n",
      "false\t0.3024\n",
      "false\t0.2092\n",
      "false\t0.2911\n",
      "false\t0.1390\n",
      "false\t0.3700\n",
      "false\t0.4839\n",
      "false\t0.4046\n",
      "false\t0.1832\n",
      "false\t0.3609\n",
      "false\t0.3595\n",
      "false\t0.1820\n",
      "false\t0.2190\n",
      "false\t0.2481\n",
      "false\t0.2665\n",
      "false\t0.0636\n",
      "false\t0.3149\n",
      "false\t0.1100\n",
      "false\t0.2433\n",
      "false\t0.1796\n",
      "false\t0.4219\n",
      "false\t0.1627\n",
      "false\t0.1218\n",
      "false\t0.0694\n",
      "false\t0.2989\n",
      "false\t0.2168\n",
      "false\t0.2653\n",
      "false\t0.1100\n",
      "false\t0.1007\n",
      "false\t0.1209\n",
      "false\t0.2231\n",
      "false\t0.1094\n",
      "false\t0.1793\n",
      "false\t0.0818\n",
      "false\t0.2205\n",
      "false\t0.1944\n",
      "false\t0.3405\n",
      "true\t0.5407\n",
      "false\t0.2765\n",
      "false\t0.1125\n",
      "false\t0.2052\n",
      "false\t0.3552\n",
      "false\t0.3701\n",
      "false\t0.3058\n",
      "true\t0.7779\n",
      "true\t0.5921\n",
      "true\t0.6593\n",
      "true\t0.6557\n",
      "true\t0.5762\n",
      "true\t0.5606\n",
      "true\t0.5593\n",
      "true\t0.6909\n",
      "false\t0.3646\n",
      "false\t0.2233\n",
      "false\t0.1838\n",
      "false\t0.2540\n",
      "false\t0.1520\n",
      "false\t0.3505\n",
      "false\t0.3700\n",
      "false\t0.0865\n",
      "false\t0.1180\n",
      "false\t0.2033\n",
      "false\t0.1426\n",
      "false\t0.2291\n",
      "false\t0.1477\n",
      "false\t0.1227\n",
      "false\t0.0680\n",
      "false\t0.0537\n",
      "false\t0.2944\n",
      "false\t0.1801\n",
      "false\t0.2587\n",
      "false\t0.1535\n",
      "false\t0.1330\n",
      "false\t0.1336\n",
      "false\t0.1670\n",
      "false\t0.0873\n",
      "false\t0.0937\n",
      "false\t0.0767\n",
      "false\t0.0559\n",
      "false\t0.0174\n",
      "false\t0.0205\n",
      "false\t0.0518\n",
      "false\t0.0198\n",
      "false\t0.0310\n",
      "false\t0.0232\n",
      "false\t0.0780\n",
      "false\t0.0931\n",
      "false\t0.0790\n",
      "false\t0.0798\n",
      "false\t0.0808\n",
      "false\t0.1602\n",
      "false\t0.2106\n",
      "false\t0.2008\n",
      "false\t0.1252\n",
      "false\t0.1041\n",
      "false\t0.1145\n",
      "false\t0.0583\n",
      "false\t0.0279\n",
      "false\t0.2532\n",
      "false\t0.1004\n",
      "false\t0.2230\n",
      "false\t0.0604\n",
      "false\t0.3054\n",
      "true\t0.6978\n",
      "true\t0.7969\n",
      "true\t0.7129\n",
      "true\t0.6652\n",
      "false\t0.4430\n",
      "true\t0.6390\n",
      "true\t0.8455\n",
      "false\t0.4304\n",
      "false\t0.2849\n",
      "false\t0.2727\n",
      "false\t0.1559\n",
      "false\t0.1725\n",
      "false\t0.2525\n",
      "false\t0.1248\n",
      "false\t0.2178\n",
      "false\t0.2828\n",
      "false\t0.0647\n",
      "false\t0.0822\n",
      "false\t0.1241\n",
      "false\t0.1624\n",
      "false\t0.1886\n",
      "false\t0.4136\n",
      "false\t0.1484\n",
      "false\t0.1927\n",
      "false\t0.2589\n",
      "false\t0.2216\n",
      "false\t0.2815\n",
      "false\t0.1902\n",
      "false\t0.1187\n",
      "false\t0.1890\n",
      "false\t0.1792\n",
      "false\t0.2576\n",
      "false\t0.1219\n",
      "false\t0.3696\n",
      "false\t0.1920\n",
      "false\t0.3812\n",
      "false\t0.2100\n",
      "false\t0.3300\n",
      "false\t0.2083\n",
      "false\t0.1737\n",
      "false\t0.2481\n",
      "false\t0.1790\n",
      "false\t0.2072\n",
      "false\t0.0834\n",
      "false\t0.2819\n",
      "false\t0.1990\n",
      "false\t0.4927\n",
      "false\t0.2348\n",
      "false\t0.2294\n",
      "false\t0.2161\n",
      "false\t0.2004\n",
      "false\t0.1515\n",
      "false\t0.2753\n",
      "false\t0.3616\n",
      "false\t0.3660\n",
      "false\t0.2730\n",
      "true\t0.5606\n",
      "false\t0.3405\n",
      "false\t0.2073\n",
      "false\t0.1766\n",
      "false\t0.2746\n",
      "false\t0.1906\n",
      "false\t0.1939\n",
      "false\t0.0854\n",
      "false\t0.0701\n",
      "false\t0.0611\n",
      "false\t0.1226\n",
      "false\t0.3951\n",
      "false\t0.2325\n",
      "false\t0.3291\n",
      "false\t0.1038\n",
      "false\t0.3689\n",
      "false\t0.3481\n",
      "false\t0.1885\n",
      "false\t0.3747\n",
      "false\t0.2395\n",
      "false\t0.2290\n",
      "false\t0.2528\n",
      "false\t0.1766\n",
      "false\t0.2807\n",
      "false\t0.1146\n",
      "false\t0.3649\n",
      "false\t0.1395\n",
      "false\t0.1039\n",
      "false\t0.4253\n",
      "false\t0.1465\n",
      "false\t0.1723\n",
      "false\t0.1519\n",
      "false\t0.2651\n",
      "false\t0.0583\n",
      "false\t0.2017\n",
      "false\t0.1571\n",
      "false\t0.1063\n",
      "false\t0.1085\n",
      "false\t0.0295\n",
      "false\t0.2301\n",
      "false\t0.0731\n",
      "false\t0.3110\n",
      "false\t0.3357\n",
      "false\t0.2007\n",
      "false\t0.2498\n",
      "false\t0.2978\n",
      "false\t0.1026\n",
      "false\t0.1188\n",
      "false\t0.2507\n",
      "false\t0.1520\n",
      "false\t0.1880\n",
      "false\t0.0879\n",
      "false\t0.0330\n",
      "false\t0.0308\n",
      "false\t0.0906\n",
      "false\t0.0392\n",
      "false\t0.0178\n",
      "false\t0.0355\n",
      "false\t0.0942\n",
      "false\t0.1566\n",
      "false\t0.0923\n",
      "false\t0.1501\n",
      "false\t0.1514\n",
      "false\t0.0534\n",
      "false\t0.1828\n",
      "false\t0.3384\n",
      "false\t0.3784\n",
      "false\t0.2574\n",
      "false\t0.1903\n",
      "false\t0.0816\n",
      "false\t0.0893\n",
      "false\t0.0783\n",
      "false\t0.0703\n",
      "false\t0.3332\n",
      "false\t0.1591\n",
      "false\t0.1407\n",
      "false\t0.0415\n",
      "false\t0.0279\n",
      "false\t0.0380\n",
      "false\t0.1944\n",
      "false\t0.1498\n",
      "false\t0.0625\n",
      "false\t0.0616\n",
      "false\t0.4833\n",
      "false\t0.0461\n",
      "false\t0.0592\n",
      "false\t0.1360\n",
      "false\t0.0436\n",
      "false\t0.0773\n",
      "false\t0.0728\n",
      "false\t0.2135\n",
      "false\t0.2253\n",
      "false\t0.2084\n",
      "false\t0.2060\n",
      "false\t0.2191\n",
      "false\t0.1264\n",
      "false\t0.1654\n",
      "false\t0.1650\n",
      "false\t0.1785\n",
      "false\t0.1279\n",
      "false\t0.2940\n",
      "false\t0.4293\n",
      "false\t0.2516\n",
      "false\t0.0883\n",
      "false\t0.1692\n",
      "false\t0.1810\n",
      "false\t0.0466\n",
      "false\t0.0774\n",
      "false\t0.1769\n",
      "true\t0.5944\n",
      "false\t0.3563\n",
      "false\t0.4069\n",
      "false\t0.3416\n",
      "false\t0.3990\n",
      "false\t0.4866\n",
      "true\t0.6020\n",
      "false\t0.3309\n",
      "false\t0.4652\n",
      "false\t0.2799\n",
      "false\t0.2475\n",
      "true\t0.5661\n",
      "false\t0.4652\n",
      "false\t0.2874\n",
      "false\t0.3601\n",
      "true\t0.8134\n",
      "false\t0.4791\n",
      "true\t0.7372\n",
      "false\t0.4532\n",
      "true\t0.6664\n",
      "false\t0.4814\n",
      "false\t0.4054\n",
      "false\t0.4769\n",
      "true\t0.5775\n",
      "false\t0.3726\n",
      "false\t0.3328\n",
      "false\t0.2543\n",
      "false\t0.1398\n",
      "false\t0.0837\n",
      "false\t0.1060\n",
      "false\t0.0888\n",
      "false\t0.0640\n",
      "false\t0.1264\n",
      "false\t0.0471\n",
      "false\t0.0947\n",
      "false\t0.0981\n",
      "false\t0.0868\n",
      "false\t0.1169\n",
      "false\t0.0406\n",
      "false\t0.0620\n",
      "false\t0.0335\n",
      "false\t0.0953\n",
      "false\t0.0287\n",
      "false\t0.0990\n",
      "false\t0.1084\n",
      "false\t0.1636\n",
      "false\t0.1941\n",
      "false\t0.1029\n",
      "false\t0.1014\n",
      "false\t0.1714\n",
      "false\t0.2675\n",
      "false\t0.3511\n",
      "false\t0.2917\n",
      "false\t0.4347\n",
      "false\t0.2599\n",
      "false\t0.1705\n",
      "false\t0.2636\n",
      "false\t0.4123\n",
      "false\t0.3678\n",
      "false\t0.3973\n",
      "false\t0.1727\n",
      "false\t0.2433\n",
      "false\t0.2691\n",
      "false\t0.4828\n",
      "false\t0.2573\n",
      "false\t0.4242\n",
      "true\t0.5671\n",
      "false\t0.2642\n",
      "false\t0.1816\n",
      "false\t0.4631\n",
      "false\t0.4248\n",
      "false\t0.2766\n",
      "false\t0.3505\n",
      "false\t0.3893\n",
      "false\t0.1855\n",
      "false\t0.3098\n",
      "false\t0.2794\n",
      "false\t0.4069\n",
      "false\t0.3651\n",
      "false\t0.3175\n",
      "false\t0.3469\n",
      "false\t0.3391\n",
      "false\t0.4437\n",
      "false\t0.3385\n",
      "false\t0.2213\n",
      "false\t0.1673\n",
      "false\t0.2051\n",
      "false\t0.2470\n",
      "false\t0.2243\n",
      "false\t0.2070\n",
      "false\t0.1948\n",
      "false\t0.1882\n",
      "true\t0.6104\n",
      "true\t0.5515\n",
      "false\t0.3835\n",
      "false\t0.3381\n",
      "false\t0.4077\n",
      "false\t0.3593\n",
      "true\t0.7554\n",
      "true\t0.7985\n",
      "false\t0.2478\n",
      "false\t0.4335\n",
      "true\t0.7316\n",
      "false\t0.3202\n",
      "false\t0.1766\n",
      "false\t0.4087\n",
      "false\t0.4415\n",
      "false\t0.3626\n",
      "false\t0.3723\n",
      "false\t0.4138\n",
      "false\t0.1829\n",
      "false\t0.3140\n",
      "false\t0.5000\n",
      "false\t0.4444\n",
      "true\t0.5256\n",
      "false\t0.1915\n",
      "false\t0.2429\n",
      "false\t0.0843\n",
      "false\t0.1666\n",
      "false\t0.0848\n",
      "false\t0.2176\n",
      "false\t0.4305\n",
      "false\t0.1472\n",
      "false\t0.0872\n",
      "false\t0.1298\n",
      "false\t0.0851\n",
      "false\t0.0690\n",
      "false\t0.1295\n",
      "false\t0.2286\n",
      "false\t0.2354\n",
      "false\t0.0955\n",
      "false\t0.1405\n",
      "false\t0.1185\n",
      "false\t0.2406\n",
      "false\t0.1043\n",
      "false\t0.1019\n",
      "false\t0.1451\n",
      "false\t0.1624\n",
      "false\t0.0879\n",
      "false\t0.0989\n",
      "false\t0.1022\n",
      "false\t0.1748\n",
      "false\t0.2122\n",
      "false\t0.1127\n",
      "false\t0.2159\n",
      "false\t0.2854\n",
      "false\t0.1136\n",
      "false\t0.1305\n",
      "false\t0.3528\n",
      "false\t0.2695\n",
      "false\t0.1979\n",
      "false\t0.1903\n",
      "false\t0.3118\n",
      "false\t0.4333\n",
      "false\t0.2116\n",
      "false\t0.2665\n",
      "true\t0.5333\n",
      "false\t0.4092\n",
      "false\t0.2910\n",
      "false\t0.2875\n",
      "false\t0.2313\n",
      "false\t0.4137\n",
      "false\t0.1180\n",
      "false\t0.4874\n",
      "false\t0.1819\n",
      "false\t0.2635\n",
      "false\t0.2468\n",
      "false\t0.4335\n",
      "false\t0.2486\n",
      "false\t0.3223\n",
      "false\t0.0812\n",
      "false\t0.1139\n",
      "false\t0.0515\n",
      "false\t0.1290\n",
      "false\t0.0507\n",
      "false\t0.0673\n",
      "false\t0.0987\n",
      "false\t0.0456\n",
      "false\t0.0897\n",
      "false\t0.0908\n",
      "false\t0.3412\n",
      "false\t0.2202\n",
      "false\t0.0720\n",
      "false\t0.0587\n",
      "false\t0.0498\n",
      "false\t0.2103\n",
      "false\t0.1202\n",
      "false\t0.1508\n",
      "false\t0.3843\n",
      "false\t0.2068\n",
      "false\t0.0736\n",
      "false\t0.1171\n",
      "false\t0.0794\n",
      "false\t0.0334\n",
      "false\t0.0778\n",
      "false\t0.1183\n",
      "false\t0.1692\n",
      "false\t0.1161\n",
      "false\t0.2228\n",
      "false\t0.1485\n",
      "false\t0.0796\n",
      "false\t0.1487\n",
      "false\t0.0857\n",
      "false\t0.2363\n",
      "false\t0.2900\n",
      "false\t0.2068\n",
      "false\t0.1150\n",
      "false\t0.0785\n",
      "false\t0.1303\n",
      "false\t0.1485\n",
      "false\t0.1432\n",
      "false\t0.0788\n",
      "false\t0.2158\n",
      "false\t0.1356\n",
      "false\t0.1003\n",
      "false\t0.4359\n",
      "false\t0.1487\n",
      "true\t0.5213\n",
      "false\t0.3990\n",
      "false\t0.3066\n",
      "true\t0.5115\n",
      "false\t0.3990\n",
      "false\t0.5000\n",
      "false\t0.3936\n",
      "false\t0.3150\n",
      "true\t0.5652\n",
      "true\t0.5577\n",
      "true\t0.5464\n",
      "false\t0.4922\n",
      "true\t0.5091\n",
      "false\t0.4128\n",
      "true\t0.5852\n",
      "false\t0.3492\n",
      "false\t0.4576\n",
      "true\t0.6534\n",
      "true\t0.5101\n",
      "false\t0.3780\n",
      "false\t0.3959\n",
      "true\t0.5939\n",
      "true\t0.6170\n",
      "true\t0.7101\n",
      "true\t0.6631\n",
      "false\t0.3334\n",
      "false\t0.1910\n",
      "false\t0.3445\n",
      "false\t0.3911\n",
      "false\t0.3984\n",
      "false\t0.1375\n",
      "false\t0.3731\n",
      "false\t0.3886\n",
      "false\t0.5000\n",
      "true\t0.6711\n",
      "false\t0.4548\n",
      "false\t0.4188\n",
      "true\t0.6316\n",
      "false\t0.3860\n",
      "false\t0.1759\n",
      "false\t0.4242\n",
      "false\t0.2232\n",
      "false\t0.1823\n",
      "false\t0.4655\n",
      "true\t0.5132\n",
      "true\t0.5458\n",
      "false\t0.3539\n",
      "true\t0.5090\n",
      "true\t0.5445\n",
      "true\t0.6059\n",
      "false\t0.2212\n",
      "false\t0.3067\n",
      "true\t0.9089\n",
      "true\t0.8194\n",
      "true\t0.8881\n",
      "true\t0.8560\n",
      "true\t0.9232\n",
      "true\t0.9113\n",
      "true\t0.9266\n",
      "true\t0.9162\n",
      "true\t0.9020\n",
      "false\t0.3932\n",
      "false\t0.4842\n",
      "true\t0.6682\n",
      "true\t0.5329\n",
      "false\t0.4435\n",
      "false\t0.4862\n",
      "true\t0.8875\n",
      "true\t0.7878\n",
      "true\t0.9805\n",
      "true\t0.8338\n",
      "true\t0.6979\n",
      "true\t0.9520\n",
      "false\t0.2544\n",
      "false\t0.1180\n",
      "false\t0.2262\n",
      "false\t0.2298\n",
      "false\t0.1306\n",
      "false\t0.1738\n",
      "false\t0.1878\n",
      "false\t0.1389\n",
      "false\t0.2099\n",
      "false\t0.0451\n",
      "false\t0.0299\n",
      "false\t0.1045\n",
      "false\t0.0828\n",
      "false\t0.0852\n",
      "false\t0.1695\n",
      "false\t0.0597\n",
      "false\t0.0428\n",
      "false\t0.0605\n",
      "false\t0.0449\n",
      "false\t0.0690\n",
      "false\t0.0536\n",
      "true\t0.5671\n",
      "false\t0.2016\n",
      "false\t0.3817\n",
      "false\t0.3869\n",
      "false\t0.4481\n",
      "false\t0.3602\n",
      "false\t0.2633\n",
      "false\t0.3031\n",
      "false\t0.2947\n",
      "false\t0.3766\n",
      "false\t0.2632\n",
      "true\t0.5542\n",
      "false\t0.3308\n",
      "false\t0.2364\n",
      "false\t0.3393\n",
      "false\t0.4151\n",
      "false\t0.2206\n",
      "false\t0.2364\n",
      "false\t0.2374\n",
      "false\t0.1775\n",
      "false\t0.3194\n",
      "false\t0.3004\n",
      "false\t0.3210\n",
      "false\t0.1556\n",
      "false\t0.2253\n",
      "true\t0.6318\n",
      "false\t0.5000\n",
      "true\t0.6108\n",
      "false\t0.2532\n",
      "true\t0.6277\n",
      "true\t0.5992\n",
      "true\t0.7277\n",
      "false\t0.4924\n",
      "true\t0.6277\n",
      "true\t0.7823\n",
      "true\t0.5120\n",
      "false\t0.4812\n",
      "true\t0.6230\n",
      "false\t0.3005\n",
      "false\t0.4230\n",
      "true\t0.5940\n",
      "false\t0.3879\n",
      "false\t0.4016\n",
      "false\t0.3722\n",
      "true\t0.6036\n",
      "false\t0.4706\n",
      "true\t0.5681\n",
      "true\t0.7900\n",
      "true\t0.6553\n",
      "true\t0.6938\n",
      "false\t0.3688\n",
      "false\t0.2861\n",
      "false\t0.1153\n",
      "false\t0.3798\n",
      "false\t0.2683\n",
      "false\t0.3051\n",
      "false\t0.1818\n",
      "false\t0.3585\n",
      "false\t0.4141\n",
      "false\t0.2330\n",
      "false\t0.2108\n",
      "false\t0.2745\n",
      "false\t0.2208\n",
      "false\t0.1505\n",
      "false\t0.3763\n",
      "false\t0.1658\n",
      "false\t0.2332\n",
      "false\t0.2496\n",
      "false\t0.2027\n",
      "false\t0.2740\n",
      "false\t0.2240\n",
      "false\t0.1125\n",
      "false\t0.2582\n",
      "false\t0.3990\n",
      "false\t0.2688\n",
      "false\t0.2970\n",
      "false\t0.2246\n",
      "false\t0.1499\n",
      "false\t0.1103\n",
      "false\t0.3797\n",
      "false\t0.2797\n",
      "false\t0.4819\n",
      "false\t0.2861\n",
      "false\t0.3469\n",
      "false\t0.1212\n",
      "false\t0.1769\n",
      "false\t0.0626\n",
      "false\t0.1630\n",
      "false\t0.1510\n",
      "false\t0.2132\n",
      "false\t0.1798\n",
      "false\t0.0828\n",
      "false\t0.0781\n",
      "false\t0.1264\n",
      "false\t0.1382\n",
      "false\t0.2403\n",
      "false\t0.1445\n",
      "false\t0.2212\n",
      "false\t0.1984\n",
      "false\t0.1133\n",
      "false\t0.2247\n",
      "false\t0.1033\n",
      "false\t0.0943\n",
      "false\t0.1073\n",
      "false\t0.0666\n",
      "false\t0.0958\n",
      "false\t0.3792\n",
      "false\t0.4871\n",
      "false\t0.4184\n",
      "false\t0.2259\n",
      "true\t0.7309\n",
      "false\t0.0427\n",
      "false\t0.0594\n",
      "false\t0.1441\n",
      "false\t0.3083\n",
      "false\t0.3851\n",
      "false\t0.2695\n",
      "false\t0.3078\n",
      "false\t0.1566\n",
      "false\t0.1367\n",
      "false\t0.1456\n",
      "false\t0.0721\n",
      "false\t0.1107\n",
      "false\t0.1274\n",
      "false\t0.2578\n",
      "false\t0.1490\n",
      "false\t0.0728\n",
      "false\t0.0243\n",
      "false\t0.0984\n",
      "false\t0.1192\n",
      "false\t0.1503\n",
      "false\t0.1746\n",
      "false\t0.1031\n",
      "false\t0.1032\n",
      "false\t0.1251\n",
      "false\t0.1939\n",
      "false\t0.1740\n",
      "false\t0.2180\n",
      "false\t0.1618\n",
      "false\t0.0664\n",
      "false\t0.1942\n",
      "false\t0.2717\n",
      "false\t0.3512\n",
      "false\t0.3368\n",
      "false\t0.2919\n",
      "false\t0.4124\n",
      "false\t0.4738\n",
      "true\t0.6743\n",
      "false\t0.2195\n",
      "false\t0.2386\n",
      "false\t0.1057\n",
      "false\t0.2598\n",
      "false\t0.2124\n",
      "false\t0.4068\n",
      "false\t0.2806\n",
      "false\t0.1348\n",
      "false\t0.3916\n",
      "false\t0.1396\n",
      "false\t0.2444\n",
      "false\t0.2138\n",
      "false\t0.3778\n",
      "false\t0.1843\n",
      "false\t0.0540\n",
      "false\t0.0896\n",
      "false\t0.0844\n",
      "false\t0.1315\n",
      "false\t0.0826\n",
      "false\t0.1205\n",
      "false\t0.0857\n",
      "false\t0.1884\n",
      "false\t0.0458\n",
      "false\t0.2904\n",
      "false\t0.1122\n",
      "false\t0.3150\n",
      "false\t0.3623\n",
      "false\t0.1306\n",
      "false\t0.3862\n",
      "false\t0.2716\n",
      "false\t0.3140\n",
      "false\t0.3459\n",
      "false\t0.1487\n",
      "false\t0.1688\n",
      "false\t0.1494\n",
      "false\t0.2514\n",
      "false\t0.1779\n",
      "false\t0.2055\n",
      "false\t0.2900\n",
      "false\t0.1910\n",
      "false\t0.2256\n",
      "false\t0.1487\n",
      "false\t0.2189\n",
      "false\t0.1311\n",
      "false\t0.2641\n",
      "false\t0.1177\n",
      "false\t0.2022\n",
      "false\t0.1977\n",
      "false\t0.0857\n",
      "false\t0.2418\n",
      "false\t0.0999\n",
      "false\t0.2316\n",
      "false\t0.1628\n",
      "false\t0.0463\n",
      "false\t0.1653\n",
      "false\t0.1151\n",
      "false\t0.0839\n",
      "false\t0.2392\n",
      "false\t0.1445\n",
      "false\t0.2089\n",
      "false\t0.2142\n",
      "false\t0.1329\n",
      "false\t0.2371\n",
      "false\t0.1672\n",
      "false\t0.1557\n",
      "false\t0.2734\n",
      "false\t0.1467\n",
      "false\t0.2036\n",
      "false\t0.0892\n",
      "false\t0.0763\n",
      "false\t0.1155\n",
      "false\t0.2802\n",
      "false\t0.1762\n",
      "false\t0.2197\n",
      "false\t0.1312\n",
      "false\t0.1286\n",
      "false\t0.2260\n",
      "false\t0.1584\n",
      "false\t0.1396\n",
      "false\t0.1690\n",
      "false\t0.1407\n",
      "false\t0.1700\n",
      "false\t0.1380\n",
      "false\t0.2112\n",
      "false\t0.3195\n",
      "false\t0.2044\n",
      "false\t0.5000\n",
      "false\t0.5000\n",
      "false\t0.4168\n",
      "false\t0.1983\n",
      "false\t0.1043\n",
      "false\t0.4438\n",
      "false\t0.2690\n",
      "false\t0.2923\n",
      "false\t0.1942\n",
      "false\t0.3342\n",
      "false\t0.0672\n",
      "false\t0.0927\n",
      "false\t0.1135\n",
      "false\t0.1455\n",
      "false\t0.0782\n",
      "false\t0.1261\n",
      "false\t0.1280\n",
      "false\t0.0953\n",
      "false\t0.1078\n",
      "false\t0.1673\n",
      "false\t0.1584\n",
      "false\t0.0785\n",
      "false\t0.0550\n",
      "false\t0.0417\n",
      "false\t0.1220\n",
      "false\t0.1037\n",
      "false\t0.0909\n",
      "false\t0.1916\n",
      "false\t0.1878\n",
      "false\t0.0624\n",
      "false\t0.1722\n",
      "false\t0.0910\n",
      "false\t0.0879\n",
      "false\t0.1209\n",
      "false\t0.1531\n",
      "false\t0.1732\n",
      "false\t0.1771\n",
      "false\t0.2103\n",
      "false\t0.0674\n",
      "false\t0.0197\n",
      "false\t0.0678\n",
      "false\t0.1205\n",
      "false\t0.2313\n",
      "false\t0.2784\n",
      "false\t0.1269\n",
      "false\t0.1756\n",
      "false\t0.1842\n",
      "false\t0.0819\n",
      "false\t0.0597\n",
      "false\t0.0696\n",
      "false\t0.1858\n",
      "false\t0.1791\n",
      "false\t0.0603\n",
      "false\t0.2395\n",
      "false\t0.3098\n",
      "false\t0.1625\n",
      "false\t0.0600\n",
      "false\t0.0859\n",
      "false\t0.1107\n",
      "false\t0.1129\n",
      "false\t0.1222\n",
      "false\t0.1196\n",
      "false\t0.1126\n",
      "false\t0.1456\n",
      "false\t0.2468\n",
      "false\t0.2470\n",
      "false\t0.1878\n",
      "false\t0.2778\n",
      "false\t0.1119\n",
      "false\t0.1682\n",
      "false\t0.2098\n",
      "false\t0.1062\n",
      "false\t0.1121\n",
      "false\t0.1149\n",
      "false\t0.0984\n",
      "false\t0.0936\n",
      "false\t0.0996\n",
      "false\t0.0789\n",
      "false\t0.2422\n",
      "false\t0.1800\n",
      "false\t0.1915\n",
      "false\t0.1135\n",
      "false\t0.1096\n",
      "false\t0.0362\n",
      "false\t0.2809\n",
      "false\t0.0541\n",
      "false\t0.1474\n",
      "false\t0.3369\n",
      "false\t0.0707\n",
      "false\t0.0893\n",
      "false\t0.0711\n",
      "false\t0.0878\n",
      "false\t0.2769\n",
      "false\t0.2596\n",
      "false\t0.1975\n",
      "false\t0.2355\n",
      "false\t0.1881\n",
      "false\t0.3143\n",
      "false\t0.0815\n",
      "false\t0.0495\n",
      "false\t0.0605\n",
      "false\t0.0509\n",
      "false\t0.2801\n",
      "false\t0.4191\n",
      "false\t0.2633\n",
      "false\t0.2034\n",
      "false\t0.0361\n",
      "false\t0.1842\n",
      "false\t0.1135\n",
      "false\t0.0465\n"
     ]
    }
   ],
   "source": [
    "for prediction in predictions:\n",
    "    label = np.argmax(prediction)\n",
    "    if prediction[1] > 0.5:\n",
    "        print('true\\t' + \"{0:.4f}\".format(prediction[1]))\n",
    "    else:\n",
    "        print('false\\t' + \"{0:.4f}\".format(prediction[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
